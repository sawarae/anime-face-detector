# Anime Face Detector (Pure PyTorch)
[![MIT License](https://img.shields.io/badge/license-MIT-green)](https://opensource.org/licenses/MIT)
[![GitHub stars](https://img.shields.io/github/stars/hysts/anime-face-detector.svg?style=flat-square&logo=github&label=Stars&logoColor=white)](https://github.com/hysts/anime-face-detector)

**Pure PyTorch implementation** of anime face detector using **YOLOv8** (face detection) and **HRNetV2** (28-point landmark detection).

⚠️ **This is a refactored version** that removes all mmdetection/mmpose/mmcv dependencies in favor of pure PyTorch.

![](https://raw.githubusercontent.com/hysts/anime-face-detector/main/assets/output.jpg)
(To avoid copyright issues, the above demo uses images generated by the
[TADNE](https://thisanimedoesnotexist.ai/) model.)

The model detects near-frontal anime faces and predicts 28 landmark points.
![](https://raw.githubusercontent.com/hysts/anime-face-detector/main/assets/landmarks.jpg)

The result of k-means clustering of landmarks detected in real images:
![](https://raw.githubusercontent.com/hysts/anime-face-detector/main/assets/cluster_pts.png)

The mean images of real images belonging to each cluster:
![](https://raw.githubusercontent.com/hysts/anime-face-detector/main/assets/cluster_mean.jpg)

## Features

- ✅ **Pure PyTorch**: No mmdetection/mmpose/mmcv dependencies
- ✅ **Lightweight**: Minimal dependencies
- ✅ **Fast**: YOLOv8-based face detection
- ✅ **Accurate**: HRNetV2-based 28-point landmark detection
- ✅ **Auto-download**: Models are automatically downloaded on first use

## Requirements

- Python 3.10-3.11
- PyTorch >= 2.0.0
- torchvision >= 0.15.0
- opencv-python-headless >= 4.5.4.58
- ultralytics >= 8.0.0 (YOLOv8)
- huggingface-hub >= 0.20.0
- numpy >= 1.21.3, < 2.0

## Installation

```bash
# Install PyTorch (if not already installed)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# Install the package
pip install ultralytics huggingface-hub opencv-python-headless numpy

# Clone and install this package
git clone https://github.com/hysts/anime-face-detector
cd anime-face-detector
pip install -e .
```

Or install all dependencies at once:

```bash
pip install -e .
```

## Quick Start

### Basic Usage

```python
from anime_face_detector import create_detector
import cv2

# Create detector (models auto-download on first use)
detector = create_detector(device='cuda:0')  # or 'cpu'

# Load image
image = cv2.imread('anime_face.jpg')

# Run inference
results = detector(image)

# Process results
for result in results:
    bbox = result['bbox']  # [x0, y0, x1, y1, score]
    keypoints = result['keypoints']  # [[x, y, score], ...] (28 points)

    print(f'Face detected at: {bbox[:4]}')
    print(f'Confidence: {bbox[4]:.3f}')
```

### Using Custom Models

```python
# Custom YOLOv8 face detector
detector = create_detector(
    face_detector_checkpoint_path='path/to/your_yolov8.pt',
    device='cuda:0'
)

# Custom HRNetV2 landmark detector
detector = create_detector(
    landmark_checkpoint_path='path/to/your_hrnetv2.pth',
    device='cuda:0'
)

# Both custom
detector = create_detector(
    face_detector_checkpoint_path='path/to/your_yolov8.pt',
    landmark_checkpoint_path='path/to/your_hrnetv2.pth',
    device='cuda:0'
)
```

### Default Models

The package automatically downloads the following models on first use:

- **YOLOv8**: `face_yolov8n.pt` from [Bingsu/adetailer](https://huggingface.co/Bingsu/adetailer)
- **HRNetV2**: `mmpose_anime-face_hrnetv2.pth` from [GitHub Releases](https://github.com/hysts/anime-face-detector/releases/tag/v0.0.1)

### Output Format

Each detection result contains:

```python
{
    'bbox': array([x0, y0, x1, y1, score]),  # Bounding box coordinates and confidence
    'keypoints': array([
        [x, y, score],  # 28 landmark points with confidence scores
        ...
    ])
}
```

Example output:
```python
{'bbox': array([2245.0, 1594.0, 2411.6, 1745.8, 0.999], dtype=float32),
 'keypoints': array([[2259.4, 1668.0, 0.932],  # Point 0: Face outline
                     [2282.5, 1705.2, 0.872],  # Point 1: Face outline
                     # ... 26 more points ...
                     [2337.9, 1711.8, 0.979]], dtype=float32)}  # Point 27: Mouth
```

## Architecture

### Two-Stage Detection Pipeline

1. **Face Detection**: YOLOv8 (Ultralytics) detects face bounding boxes
2. **Landmark Detection**: HRNetV2 (Pure PyTorch) predicts 28 landmark points

### HRNetV2 Architecture

- **Input**: 256x256 RGB image
- **Backbone**: 4-stage multi-scale branches (18, 36, 72, 144 channels)
- **Head**: Concatenate all branches (270 channels) → 28-channel heatmap
- **Output**: 28 keypoint coordinates with confidence scores

### 28-Point Landmarks

- 0-4: Face outline
- 5-10: Eyebrows
- 11-13, 17-19: Eyes
- 14-16: Nose
- 20-27: Mouth

### Pretrained Models

Models are automatically downloaded on first use:

- **YOLOv8**: [face_yolov8n.pt](https://huggingface.co/Bingsu/adetailer) from Hugging Face
- **HRNetV2**: [mmpose_anime-face_hrnetv2.pth](https://github.com/hysts/anime-face-detector/releases/tag/v0.0.1) from GitHub Releases

## Demo (using [Gradio](https://github.com/gradio-app/gradio))
[![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-orange)](https://huggingface.co/spaces/ayousanz/anime-face-detector-gpu)

### Run locally
```bash
pip install "gradio>=5.0.0"
git clone https://github.com/hysts/anime-face-detector
cd anime-face-detector

python demo_gradio.py
```

**Note:** For Gradio version compatibility, use Gradio 5.x or later. If you have an older version:
```bash
pip install --upgrade "gradio>=5.0.0"
```

## Migration from Original Version

### Key Changes

This version removes all OpenMMLab dependencies (mmdetection, mmpose, mmcv) in favor of pure PyTorch.

**API Changes:**

```python
# Old version (mmdetection/mmpose)
from anime_face_detector import create_detector
detector = create_detector('yolov3', device='cuda:0')

# New version (pure PyTorch)
from anime_face_detector import create_detector
detector = create_detector(device='cuda:0')  # Uses YOLOv8 by default
```

**Benefits:**
- ✅ Simpler installation (no mmcv compilation required)
- ✅ Fewer dependencies
- ✅ Faster setup
- ✅ Same output format (backward compatible)

**Migration Steps:**

1. Uninstall old dependencies:
   ```bash
   pip uninstall mmdet mmpose mmcv mmengine
   ```

2. Install new version:
   ```bash
   pip install torch torchvision ultralytics huggingface-hub
   ```

3. Update your code (if needed):
   ```python
   # Simply remove the detector name argument
   detector = create_detector(device='cuda:0')
   ```

## Citation
If you find this repo useful for your research, please consider citing it:
```bibtex
@misc{anime-face-detector,
  author = {hysts},
  title = {Anime Face Detector},
  year = {2021},
  howpublished = {\url{https://github.com/hysts/anime-face-detector}}
}
```

## Links
### General
- https://github.com/open-mmlab/mmdetection
- https://github.com/open-mmlab/mmpose

### Anime face detection
- https://github.com/zymk9/yolov5_anime [![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-orange)](https://huggingface.co/spaces/hysts/yolov5_anime)
- https://github.com/qhgz2013/anime-face-detector
- https://github.com/cheese-roll/light-anime-face-detector
- https://github.com/nagadomi/lbpcascade_animeface [![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-orange)](https://huggingface.co/spaces/hysts/lbpcascade_animeface)

### Anime face landmark detection
- https://github.com/kanosawa/anime_face_landmark_detection [![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-orange)](https://huggingface.co/spaces/hysts/anime_face_landmark_detection)

### Others
- https://www.gwern.net/Faces
- https://thisanimedoesnotexist.ai
